## OptiMethods

- `SparsifiedOptimization.md`
    1. 稀疏优化 and 组稀疏优化
- `SWALP.md` — https://arxiv.org/abs/1904.11943
    1. 《SWALP : Stochastic Weight Averaging in Low-Precision Training》
- `Universal Mirror-Prox.md` — https://arxiv.org/abs/1902.01637
    1. 《A Universal Algorithm for Variational Inequalities Adaptive to Smoothness and Noise》


- 《Accelerating Stochastic Gradient Descent using Predictive Variance Reduction》—— ZhangTong
- 《Dissecting Adam: The Sign, Magnitude and Variance of Stochastic Gradients》

**Sign**
- 《signSGD: Compressed Optimisation for Non-Convex Problems》
- 《signSGD via Zeroth-Order Oracle》


**Zeroth-Order**
- 《Zeroth-Order Online Alternating Direction Method of Multipliers: Convergence Analysis and Applications》
- 《Zeroth-Order Optimization and Its Application to Adversarial Machine Learning》
- 《Zeroth-Order Stochastic Variance Reduction for Nonconvex Optimization》
- 《Zeroth-Order Stochastic Projected Gradient Descent for Nonconvex Optimization》


